{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e7bd76a4",
      "metadata": {
        "id": "e7bd76a4"
      },
      "source": [
        "\n",
        "# Structural Damage Classification using Artificial Immune Recognition System (AIRS)\n",
        "\n",
        "## Problem Statement\n",
        "The goal is to apply the Artificial Immune Pattern Recognition System (AIRS) to classify structures into **Healthy** and **Damaged** categories based on provided features.\n",
        "\n",
        "**Artificial Immune System (AIS)** is inspired by the biological immune system. It uses concepts such as **detectors**, **hypermutation**, and **pattern recognition** to solve classification problems.\n",
        "\n",
        "In this project:\n",
        "- We simulate structural health monitoring using synthetic data.\n",
        "- Train a simple AIRS classifier.\n",
        "- Evaluate its performance on unseen (test) data.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0f7e490b",
      "metadata": {
        "id": "0f7e490b"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Import Libraries\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3454044d",
      "metadata": {
        "id": "3454044d"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Set Random Seed\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5cd8e5b7",
      "metadata": {
        "id": "5cd8e5b7"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Generate Better Dummy Data (Enhanced Class Separation)\n",
        "def generate_dummy_data(samples=2000, features=10):\n",
        "    data = np.random.rand(samples, features)\n",
        "    labels = (np.sum(data, axis=1) > (features / 2)).astype(int)  # Simple binary classification logic\n",
        "    return data, labels\n",
        "\n",
        "# Generate data\n",
        "data, labels = generate_dummy_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "aa02f38a",
      "metadata": {
        "id": "aa02f38a"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Define AIRS Class (Improved)\n",
        "class AIRS:\n",
        "    def __init__(self, num_detectors=100, hypermutation_rate=0.01):\n",
        "        self.num_detectors = num_detectors\n",
        "        self.hypermutation_rate = hypermutation_rate\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.detectors = []\n",
        "        unique_classes = np.unique(y)\n",
        "        for cls in unique_classes:\n",
        "            class_samples = X[y == cls]\n",
        "            selected = class_samples[np.random.choice(len(class_samples), self.num_detectors, replace=True)]\n",
        "            self.detectors.append((cls, selected))\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for sample in X:\n",
        "            best_class = None\n",
        "            best_distance = float('inf')\n",
        "            for cls, detector_set in self.detectors:\n",
        "                distances = np.linalg.norm(detector_set - sample, axis=1)\n",
        "                min_distance = np.min(distances)\n",
        "                if min_distance < best_distance:\n",
        "                    best_distance = min_distance\n",
        "                    best_class = cls\n",
        "            predictions.append(best_class)\n",
        "        return np.array(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1042411b",
      "metadata": {
        "id": "1042411b"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Split Data into Training and Testing Sets\n",
        "split_ratio = 0.8\n",
        "split_index = int(split_ratio * len(data))\n",
        "train_data, test_data = data[:split_index], data[split_index:]\n",
        "train_labels, test_labels = labels[:split_index], labels[split_index:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "026ec7e0",
      "metadata": {
        "id": "026ec7e0"
      },
      "outputs": [],
      "source": [
        "# Cell 6: Initialize and Train AIRS\n",
        "airs = AIRS(num_detectors=200, hypermutation_rate=0.005)  # Larger number of detectors\n",
        "airs.train(train_data, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3f0acd3e",
      "metadata": {
        "id": "3f0acd3e"
      },
      "outputs": [],
      "source": [
        "# Cell 7: Predict on Test Data\n",
        "predictions = airs.predict(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8a960896",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a960896",
        "outputId": "3592b2d5-8f70-4602-8fc1-5c80951cecb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.83\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Evaluate Accuracy\n",
        "accuracy = np.mean(predictions == test_labels)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}